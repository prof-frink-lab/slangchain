{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a7d688-561c-4175-acfc-a6537f6dd042",
   "metadata": {},
   "source": [
    "## Web Voyager\n",
    "\n",
    "Inspired by [LangChain](https://github.com/hwchase17/langchain) [Web Voyager](https://github.com/langchain-ai/langgraph/blob/main/examples/web-navigation/web_voyager.ipynb), the notebook showcases a [LangGraph](https://github.com/langchain-ai/langgraph/tree/main) based Web Navigator powered by [Anthropic's Claude](https://www.anthropic.com/news/claude-3-family).\n",
    "\n",
    "[WebVoyager](https://arxiv.org/abs/2401.13919) by He, et. al., is a vision-enabled web-browsing agent capable of controlling the mouse and keyboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762761a",
   "metadata": {},
   "source": [
    "<video \n",
    "    width=\"1280\"\n",
    "    height=\"720\"\n",
    "    controls>\n",
    "    <source src=\"./video/web_voyager.mp4\" type=\"video/mp4\"/>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d5d55",
   "metadata": {},
   "source": [
    "It works by viewing annotated browser screenshots for each turn, then choosing the next step to take. The agent architecture is a basic reasoning and action (ReAct) loop. \n",
    "The unique aspects of this agent are:\n",
    "- It's usage of [Set-of-Marks](https://som-gpt4v.github.io/)-like image annotations to serve as UI affordances for the agent\n",
    "- It's application in the browser by using tools to control both the mouse and keyboard\n",
    "\n",
    "The overall design looks like the following:\n",
    "\n",
    "<!-- ![Voyager Image](./img/web-voyager.excalidraw.png) -->\n",
    "<img src=\"./img/web-voyager.excalidraw.png\" width=\"50%\">\n",
    "\n",
    "Before we build, let's configure the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cf7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a47afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "  if not os.environ.get(var):\n",
    "    os.environ[var] = getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2e932-e1ce-4f2e-93e9-c8caf44b2afc",
   "metadata": {},
   "source": [
    "#### Install Agent requirements\n",
    "\n",
    "The only additional requirement we have is the [playwright](https://playwright.dev/) browser. Uncomment and install below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b70dbe-ea14-440c-99ab-9cd171d78742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  playwright > /dev/null\n",
    "# !playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a14fa9-8ca7-4a7a-9827-8fbd465b6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# This is just required for running async playwright in a Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee0f97-eb4e-4a13-b4f4-fc6439eec6a6",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "### Overview:\n",
    "\n",
    "The system encapsulates its functionality in the [WebVoyager](../../../../../../slangchain/slangchain/graphs/anthropic/web_voyager.py) class, which extends the [Chain](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/base.py) class from a custom framework. This setup allows the system to manage a sequence of actions and decisions in an automated web browsing task. The core functionality revolves around navigating web pages, interacting with elements (clicking, typing, scrolling), and dynamically making decisions based on the current state of the webpage and the outcomes of previous actions.\n",
    "\n",
    "### Key Components and Methods:\n",
    "\n",
    "- **`mark_page`:** This asynchronous method annotates a web page by marking interactive elements with bounding boxes. It leverages a JavaScript script (`mark_page.js`) to visually identify clickable elements and text fields, facilitating the interaction process. After marking, it captures a screenshot and identifies the bounding boxes for later use.\n",
    "\n",
    "- **`_create_agent`:** Initializes the agent by setting up a chain of actions that includes marking the page, interpreting the marked elements, sending prompts to the AI model (via `ChatAnthropic`), parsing the output, and deciding on the next action. This method effectively bridges the gap between visual page representation and AI-driven decision-making.\n",
    "\n",
    "- **`init_workflow_nodes`:** Constructs a state graph representing the workflow of the web navigation task. Nodes in this graph correspond to various actions (e.g., click, type, scroll), and edges define the transition from one action to another based on the agent's decisions. This method is crucial for defining the logical flow of the navigation process.\n",
    "\n",
    "- **`_acall`:** The primary asynchronous method responsible for executing the web navigation task. It initializes the browser, sets up the page, and iterates through the action chain by following the workflow defined in the state graph. This method captures the dynamic interaction with the web page, including making decisions, performing actions, and handling the outcomes until a final result is achieved.\n",
    "\n",
    "- **Action Methods (`_click`, `_type_text`, `_scroll`, `_wait`, `_go_back`, `_to_google`):** A collection of asynchronous methods that correspond to specific actions the agent can perform on a web page. These include clicking a specified element, typing text into a field, scrolling the page or an element, waiting for a specified duration, navigating back, and going to the Google homepage. Each method takes the current state as input, performs the action using Playwright commands, and returns a description of the action for logging or decision-making purposes.\n",
    "\n",
    "- **`_select_tool`:** Determines the next action to take based on the agent's current state and the prediction from the AI model. This routing function is a critical part of the decision-making process, enabling dynamic transitions between actions in the workflow.\n",
    "\n",
    "- **`_annotate`, `_format_descriptions`, `_parse`:** Utility methods that prepare the agent's state and parse its actions. `_annotate` updates the state with marked page elements and screenshots; `_format_descriptions` generates textual descriptions of the marked elements for the AI model; `_parse` converts the model's output into actionable commands.\n",
    "\n",
    "- **`_update_scratchpad`:** Updates the agent's memory (scratchpad) with the outcomes of the latest action. This method ensures the AI model has context for its decisions, incorporating the history of actions and their results.\n",
    "\n",
    "- **`from_llm`:** A class method to instantiate the [WebVoyager](../../../../../../slangchain/slangchain/graphs/anthropic/web_voyager.py) class with a specific language model (`ChatAnthropic`), setting up the necessary configurations for the navigation task.\n",
    "\n",
    "### Functionality Flow:\n",
    "\n",
    "1. **Initialization:** The system is initialized with a language model and configurations.\n",
    "2. **Workflow Setup:** It constructs a state graph defining the logical flow of actions.\n",
    "3. **Execution:** Through the `_acall` method, the system iterates over the workflow, performing web interactions based on AI decisions.\n",
    "4. **Dynamic Decision-Making:** Utilizes AI model predictions to dynamically decide on actions, managing complex navigation tasks efficiently.\n",
    "\n",
    "This architecture combines advanced asynchronous programming, AI-driven decision-making, and state management to navigate and interact with web pages, aiming to automate a wide range of online tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833f1708-bdaf-4cea-8c26-ed6f09eb8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", max_tokens=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e4da43-4f99-4c3a-9873-4dc5e76a9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slangchain.graphs.anthropic.web_navigation.web_voyager import WebVoyager\n",
    "\n",
    "\n",
    "web_voyager = WebVoyager.from_llm(\n",
    "  llm = llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7afba",
   "metadata": {},
   "source": [
    "## Run Web Voyager\n",
    "\n",
    "Now that we've created the whole agent executor, we can run it on a few questions! We'll start our browser at \"google.com\" and then let it control the rest.\n",
    "\n",
    "Below is a helper function to help print out the steps to the notebook (and display the intermediate screenshots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ff4ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 1. Type: ['7', 'WebVoyager paper arxiv']\n",
      "Steps: 1. Type: ['7', 'WebVoyager paper arxiv']\n",
      "2. Click: ['19']\n",
      "Steps: 1. Type: ['7', 'WebVoyager paper arxiv']\n",
      "2. Click: ['19']\n",
      "3. ANSWER;: ['WebVoyager is an end-to-end web agent powered by a large multimodal model that can follow user instructions by interacting with real websites. It introduces a new benchmark compiling tasks from 15 popular sites and an automatic evaluation leveraging multimodal understanding. WebVoyager achieves 59.1% task success on the benchmark, surpassing GPT-4 and earlier methods. The automatic metric agrees 85.3% with human judgment, demonstrating reliable assessment of open-ended web agents.']\n",
      "{'input': 'Could you explain the WebVoyager paper (on arxiv)?', 'output': 'WebVoyager is an end-to-end web agent powered by a large multimodal model that can follow user instructions by interacting with real websites. It introduces a new benchmark compiling tasks from 15 popular sites and an automatic evaluation leveraging multimodal understanding. WebVoyager achieves 59.1% task success on the benchmark, surpassing GPT-4 and earlier methods. The automatic metric agrees 85.3% with human judgment, demonstrating reliable assessment of open-ended web agents.'}\n"
     ]
    }
   ],
   "source": [
    "result = await web_voyager.ainvoke(input={\"input\": \"Could you explain the WebVoyager paper (on arxiv)?\"})\n",
    "print(f\"{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
